# Local LLM Chat Advanced v2.2 マニュアル

## 1. 概要
Local LLM Chat Advanced は、LM Studio のローカル LLM と対話するためのブラウザベースチャットアプリケーションです。すべてのデータはブラウザの localStorage に保存され、外部サーバーへの送信は行いません。

### 1.1 同期手順（開発者向け）
`docs/MANUAL.md` を更新した後は、次のコマンドでヘルプモード参照用ファイルを再生成します。

`node scripts/sync-manual-embed.mjs`

## 2. アプリの起動方法

### macOS
プロジェクトフォルダの `Local LLM Chat.app` をダブルクリックする。
デスクトップから起動したい場合は、`Local LLM Chat.app` を **Option + Cmd を押しながら** デスクトップにドラッグしてエイリアスを作成する。

### Windows
プロジェクトフォルダの `Local LLM Chat.bat` をダブルクリックする。
デスクトップから起動したい場合は、右クリック → `ショートカットの作成` でショートカットを作成する。

### その他
`index.html` を直接ブラウザで開いても使用できる。

## 3. 初期表示と画面構成
- タイトル: `Local LLM Chat Advanced`
- モデル選択の初期値: `モデルを選択`
- 入力欄プレースホルダー: `メッセージを入力`
- 送信ヒント: `Enter改行 / Shift+Enter送信`（設定で変更可能）
- 初回メッセージ: `ローカルLLMチャットへようこそ。モデルを選択して開始してください。`
- バージョン表示: 画面右下に `v2.0`

## 4. 上部ツールバー
左側にロゴとタイトル、右側に以下のボタンが並ぶ。

| ボタン | 機能 |
|--------|------|
| モデル選択 | 使用する LLM モデルを選ぶドロップダウン。Vision 対応モデルには `[Vision]` ラベルが表示される |
| `モデル更新` | LM Studio から利用可能なモデル一覧を再取得する |
| `比較モード` | 2つのモデルを同時に比較するモードの ON/OFF |
| `新規チャット` | 現在の会話を保存して新しい会話を開始する |
| `新しい話題` | 同じチャット内で話題をリセットする |
| `検索` | 会話内をキーワード検索する |
| `会話ログ` | 保存済み会話ログの一覧を開く |
| `設定` | 設定パネルを開く |

### モデルロード状態
モデル選択時、LM Studio へのモデル読み込み状態がツールバーに表示される。
- 読み込み中: スピナーアイコン
- 成功: 緑色で表示後、自動的に非表示
- 失敗: エラーメッセージが表示される

## 5. 検索機能
1. `検索` ボタンを押すと検索バーが表示される。
2. キーワードを入力すると、一致するメッセージがハイライトされる。
3. 一致しないメッセージは非表示になり、該当件数が表示される。
4. 検索バー右側の `×` で検索を閉じて全メッセージを再表示する。

## 6. 比較モード
1. `比較モード` をONにする。
2. `Model A` と `Model B` を選ぶ。
3. メッセージを送信すると、2つのモデルの応答が左右2カラムで同時に表示される。
4. `比較モード` をOFFにすると通常表示に戻る。

## 7. 入力エリア

### モードボタン（入力欄の上）
| ボタン | 機能 |
|--------|------|
| `プリセット` | プリセットプロンプトのポップオーバーを表示する |
| `深掘りモード` | ON にすると LLM が回答後にフォローアップ質問を自動提示する |
| `ヘルプモード` | ON にするとこのマニュアルの内容を LLM に注入し、アプリの使い方に回答できるようにする |
| `Web検索` | ON にすると送信時に SearXNG で Web 検索し、結果をコンテキストに含める |
| `自動読み上げ` | ON にすると応答完了後に自動的に音声読み上げを行う |

### 入力カード
| 要素 | 機能 |
|------|------|
| `添付` | ファイルを添付する |
| テキスト入力欄 | メッセージを入力する |
| `停止` | ストリーミング応答を中断する |
| `送信` | メッセージを送信する |

### トークン推定
入力欄の下に `~123 tokens` のように推定トークン数がリアルタイム表示される。モデルのコンテキスト長の目安として活用できる（あくまで概算値）。

## 8. ファイル添付

### 対応形式とサイズ上限
| 種類 | 対応形式 | サイズ上限 |
|------|----------|-----------|
| 画像 | JPEG, PNG, GIF, WebP, BMP | 5 MB |
| PDF | PDF | 10 MB |
| テキスト | TXT, CSV, JSON, XML, MD など | 2 MB |

### 添付方法
- `添付` ボタンをクリックしてファイルを選択する。
- メッセージ入力欄にファイルをドラッグ＆ドロップする。
- クリップボードから画像を貼り付ける（`Cmd+V` / `Ctrl+V`）。

### 添付後の表示
- 添付ファイルは入力欄の下にチップとして表示される。
- 画像はサムネイル付きで表示される。
- チップの `×` で個別に削除できる。

### 画像の自動圧縮
5 MB を超える画像、または長辺が 2048 px を超える画像は自動的にリサイズ・圧縮される。
- 長辺を 2048 px に縮小（アスペクト比維持）
- JPEG 形式で段階的に品質を下げて 5 MB 以内に収める
- 圧縮後、システムメッセージで結果が通知される

### Vision モデルについて
画像を添付して送信するには **Vision 対応モデル** が必要。モデル名に `llava`, `qwen2-vl`, `qwen3-vl`, `gemma-3`, `pixtral`, `moondream`, `bakllava`, `phi-3-vision` などを含むモデルが自動判定される。Vision 非対応モデルで画像送信すると警告が表示される。

### PDF テキスト抽出
PDF を添付するとテキストが自動抽出され LLM に送信される。ページ単位でテキストを取得し全ページ分を結合する。画像のみの PDF（スキャン画像など）はテキスト抽出できない。

## 9. メッセージ操作

### ユーザーメッセージ
| ボタン | 機能 |
|--------|------|
| `ブックマーク` | メッセージにブックマーク（星マーク）を付ける／外す |
| `編集` | メッセージを編集して再送信する |
| `削除` | メッセージを削除する |

### アシスタントメッセージ
| ボタン | 機能 |
|--------|------|
| `ブックマーク` | メッセージにブックマーク（星マーク）を付ける／外す |
| `コピー` | 応答テキストをクリップボードにコピーする |
| `読み上げ` | 応答を音声で読み上げる（再度クリックで停止） |
| `再生成` | 同じ入力で応答を再生成する |
| `再開` | 中断された応答の続きを生成する（中断時のみ表示） |
| `医学用語チェック` | 応答内の医学用語の正確性を検証する |
| `削除` | メッセージを削除する |

### ストリーミング指標
応答生成中および完了後、各メッセージの下部に以下の指標が表示される。
- **トークン数**: 応答の総トークン数
- **速度**: トークン生成速度（t/s）
- **経過時間**: 応答生成にかかった時間

## 10. 思考プロセス表示（Thinking Models）
Thinking model（推論モデル）が応答中に生成する思考プロセスを、本文と分離して折りたたみブロックで表示する機能。

### 対応するモデルの思考形式
| 形式 | 対象モデル例 |
|------|-------------|
| `<think>...</think>` | Qwen3, DeepSeek R1 |
| `<think>...`（閉じタグなし） | ストリーミング中の部分思考 |
| `...</think>`（開きタグなし） | nvidia/nemotron-3-nano |
| `<unusedNN>thought...`（閉じタグなし） | medgemma |
| `reasoning` フィールド | gpt-oss-120B（LM Studio の Reasoning API） |

### 表示
- 思考内容は折りたたみ可能な「思考プロセス」ブロックに表示される。
- ストリーミング中は「思考中…」ラベルで自動展開され、完了後に折りたたまれる。
- 本文は思考ブロックの下に通常どおり Markdown レンダリングされる。

### Reasoning Effort（推論モデル専用）
gpt-oss-120B 等の reasoning 対応モデルでは、`設定` > `接続` の `Reasoning Effort` で推論の深さを制御できる。
- `off` — reasoning パラメータを送信しない（デフォルト）
- `low` / `medium` / `high` — API リクエストに `reasoning: { effort: "..." }` を追加

Reasoning Effort が `off` 以外の場合、モデルの応答は `delta.reasoning` フィールドに思考内容、`delta.content` フィールドに本文が分離して返される。

### 思考プロセスの非表示
`設定` > `詳細モード` の `思考プロセスを非表示` を ON にすると、折りたたみブロック自体が表示されなくなる。思考内容は内部で保持されるが、画面には本文のみ表示される。

## 11. 数式表示（KaTeX）
LLM の応答に含まれる数式は KaTeX で自動レンダリングされる。

### 対応する記法
| 記法 | 用途 | 例 |
|------|------|-----|
| `$...$` | インライン数式 | `$x^2 + y^2 = r^2$` |
| `$$...$$` | ブロック数式 | `$$\sum_{i=1}^{n} x_i$$` |
| `\(...\)` | インライン数式 | `\(E = mc^2\)` |
| `\[...\]` | ブロック数式 | `\[\int_0^1 f(x)\,dx\]` |
| ` ```math ` | ブロック数式 | コードブロック内に LaTeX を記述 |

コードブロック内の数式記法は無視される（コード表示が優先）。デリミタなしのテキスト数式はレンダリング対象外。

## 12. Web検索（SearXNG）
`Web検索` ボタンを ON にすると、メッセージ送信時に自動で SearXNG にクエリを送り、検索結果をコンテキストとして LLM に渡す。SearXNG はオープンソースのメタサーチエンジンで、Google・Bing 等の検索結果をプライバシーを保護しながら集約する。

### SearXNG のセットアップ

#### 1. Docker Desktop のインストール（初回のみ）
SearXNG の実行には Docker が必要。まだインストールしていない場合は以下の手順で導入する。

**macOS の場合：**
1. https://www.docker.com/products/docker-desktop/ にアクセスする。
2. `Download for Mac` をクリックしてインストーラをダウンロードする。Apple Silicon（M1/M2/M3/M4）の場合は `Apple Chip` を選択する。
3. ダウンロードした `.dmg` ファイルを開き、Docker アイコンを Applications フォルダにドラッグする。
4. Applications フォルダから Docker を起動する。初回は権限の許可を求められるので許可する。
5. メニューバーにクジラのアイコンが表示され、`Docker Desktop is running` と出れば完了。

**Windows の場合：**
1. https://www.docker.com/products/docker-desktop/ にアクセスする。
2. `Download for Windows` をクリックしてインストーラをダウンロードする。
3. ダウンロードした `.exe` ファイルを実行し、画面の指示に従ってインストールする。
4. インストール後、PC を再起動する（WSL 2 の有効化が必要な場合がある）。
5. Docker Desktop を起動し、タスクバーにクジラのアイコンが表示されれば完了。

Docker Desktop が起動していることを確認したら、次の手順に進む。

#### 2. SearXNG の起動
プロジェクトフォルダに `docker-compose.yml` が同梱されている。

```bash
cd local_llm_chat_advanced
docker compose up -d
```

これで `http://localhost:8888` に SearXNG + nginx（CORS プロキシ）が起動する。停止する場合は `docker compose down`。

構成ファイル：
| ファイル | 役割 |
|---------|------|
| `docker-compose.yml` | SearXNG コンテナと nginx プロキシの定義 |
| `searxng/settings.yml` | SearXNG の設定（JSON API 有効化、レート制限解除） |
| `searxng/nginx.conf` | CORS ヘッダーを付与するリバースプロキシ設定 |

### 使い方
1. SearXNG サーバーをローカルで起動しておく（上記の `docker compose up -d`）。
2. `設定` > `Web検索` タブ > `Web検索を有効にする` をONにする。
3. `SearXNG URL`（デフォルト: `http://localhost:8888`）と `検索結果数`（1〜10、デフォルト: 5）を設定する。
4. 入力エリアの `Web検索`（Globe）ボタンを ON にしてメッセージを送信する。
5. キーボードショートカット `⌘/Ctrl + Shift + W` でも ON/OFF を切り替えられる。

### 動作
- 送信されたメッセージを検索クエリとして SearXNG に問い合わせる。
- 検索結果（タイトル・URL・概要）がシステムプロンプトに注入される。
- LLM は `[1]`, `[2]` のように出典番号を付けて回答できる。
- SearXNG に接続できない場合は警告メッセージが表示され、検索なしで続行される。
- 比較モードでは検索を1回実行し、両モデルに同じ検索結果を渡す。

### SearXNG の検索カテゴリ
SearXNG は複数の検索カテゴリに対応している。現在のアプリでは `general`（一般Web検索）を使用している。

| カテゴリ | 内容 | 用途例 |
|---------|------|--------|
| `general` | 一般Web検索 | 天気、ニュース、一般的な質問（現在使用中） |
| `science` | 学術論文 | PubMed・Google Scholar 経由の論文検索 |
| `news` | ニュース | 最新の学会発表、医療ニュース |
| `images` | 画像検索 | 画像所見の参考 |
| `videos` | 動画検索 | 教育動画、手技動画 |
| `it` | IT・技術 | プログラミング、技術情報 |
| `files` | ファイル検索 | PDF、ガイドライン文書 |

### 注意事項
- SearXNG 自体はインターネット接続が必要（外部検索エンジンに問い合わせるため）。
- 完全オフライン環境では使用できない。
- Web検索はデフォルトで OFF。有効にしなければ従来通りオフラインで動作する。

## 13. メモリー機能
会話の中からユーザーに関する重要な情報を自動的に抽出・保存し、以降の会話に反映する機能。

### 使い方
- `設定` > `基本` > `メモリー機能` で ON/OFF を切り替える（デフォルト: ON）。
- メモリーの管理は `設定` > `データ` > `メモリー管理` で行う。

### 動作
- LLM の応答後、バックグラウンドで会話内容を分析し、記憶すべき情報を自動抽出する。
- 抽出されるカテゴリ: プロファイル（名前・職業等）、嗜好、目標、コンテキスト情報。
- 保存されたメモリーは次回以降の会話でシステムプロンプトに自動注入される。
- 不要なメモリーは `メモリー管理` から個別に削除できる。`メモリー全削除` で一括削除も可能。

## 14. ブックマーク機能
重要なメッセージに星マークを付けて、後から素早く参照できる機能。

### 使い方
- 各メッセージ（ユーザー・アシスタント）の下部にある `ブックマーク`（星）ボタンをクリックする。
- ブックマーク済みのメッセージには金色のボーダーが表示される。
- `⌘/Ctrl + Shift + B` でブックマーク一覧モーダルを開き、ブックマーク済みメッセージを一覧表示する。
- 一覧からクリックすると、そのメッセージがある会話に移動してスクロールする。

### ブックマークの保持
- ブックマーク状態は会話ログとともに localStorage に保存される。
- 会話ログを削除するとブックマークも消える。

## 15. タイトル自動生成
新規チャットの最初のやり取り後に、LLM が会話内容から短いタイトルを自動生成する機能。

### 使い方
- `設定` > `基本` > `タイトル自動生成` で ON/OFF を切り替える（デフォルト: ON）。
- 新規チャットで1往復すると、会話ログのタイトルが自動的に更新される。
- 手動でタイトルをリネームした場合は、以降の自動上書きは行われない。
- タイトル生成はバックグラウンドで実行され、チャットの操作をブロックしない。

## 16. 音声読み上げ（TTS）
Web Speech API を使って、アシスタントの応答を音声で読み上げる機能。

### 手動読み上げ
- アシスタントメッセージの `読み上げ`（スピーカー）ボタンをクリックする。
- 読み上げ中に再度クリックすると停止する。
- 設定に関わらず常に使用可能。

### 自動読み上げ
- `設定` > `基本` > `音声` セクションで `音声読み上げを有効にする` と `新しい応答を自動読み上げ` を ON にする。
- または入力エリアの `自動読み上げ`（スピーカー）ボタンをクリックして ON にする。
- キーボードショートカット `⌘/Ctrl + Shift + T` でも ON/OFF を切り替えられる。
- ON の状態でメッセージを送信すると、応答完了後に自動的に読み上げが開始される。
- 次のメッセージを送信すると読み上げは自動停止する。

### 音声設定
| 項目 | 説明 |
|------|------|
| `音声読み上げを有効にする` | TTS 機能の有効/無効（デフォルト: OFF） |
| `新しい応答を自動読み上げ` | 応答完了後の自動読み上げ（デフォルト: OFF） |
| `音声` | 使用する音声を選択（日本語音声が優先表示される） |
| `読み上げ速度` | 0.5〜2.0 倍速（デフォルト: 1.0） |

## 17. 深掘りモード
`深掘りモード` を ON にすると、LLM が回答後に関連するフォローアップ質問を自動的に提示する。学習や調査を深めたい場合に有効。

## 18. ヘルプモード
`ヘルプモード` を ON にすると、このマニュアルの内容がシステムプロンプトに注入され、LLM がアプリの機能や操作方法について正確に回答できるようになる。

## 19. 医学用語チェック
アシスタントメッセージの `医学用語チェック` ボタンを押すと、応答内の医学用語を LLM が検証する。
- 用語の誤りや不正確な表現がある場合、元の表現・推奨表現・理由が一覧表示される。
- 問題がなければ「重大な問題なし」と表示される。
- 結果はモーダルダイアログ `医学用語チェック結果` に表示される。

## 20. 設定パネル
`設定` ボタンで開くサイドパネル。4つのタブで構成される。

### 20.1 設定 > 基本

#### セクション `入力`
| 項目 | 説明 |
|------|------|
| `送信キー` | `Enterで改行 / Shift+Enterで送信` または `Enterで送信 / Shift+Enterで改行` |
| `新規チャットでLLMから呼びかけ` | ON にすると新規チャット開始時に LLM が自動で挨拶メッセージを生成する。ユーザープロファイル（呼び名等）に応じてパーソナライズされる |
| `メモリー機能` | 会話からユーザー情報を自動抽出・保存する機能の ON/OFF |
| `ダークモード` | ダークテーマに切り替える |
| `モデル自動アンロード` | モデル切り替え時に前のモデルを LM Studio から自動アンロードする。VRAM が限られている環境で有効 |
| `タイトル自動生成` | 新規チャットの1往復後に LLM がタイトルを自動生成する（デフォルト: ON） |

#### セクション `応答スタイル`
`Response Style` で LLM の応答スタイルを選択する。
- `concise` — 簡潔に回答
- `standard` — 標準的な回答
- `detailed` — 詳細に回答
- `professional` — 専門的なトーンで回答

#### セクション `ユーザープロファイル`
| 項目 | 説明 |
|------|------|
| `レベル` | `未設定`, `beginner`, `intermediate`, `advanced`, `expert` から選択。LLM の説明の深さに影響する |
| `職業 / 専門分野` | 自由入力。LLM が専門分野に合わせた回答をする |
| `興味・関心` | 自由入力。LLM が関心に沿った補足をする |
| `呼び名` | 自由入力（例: `まさとさん`）。LLM が呼びかけに使用する |

#### セクション `詳細モード`
| 項目 | 説明 |
|------|------|
| `信頼度・代替候補（logprobs）表示` | ON にすると各応答に信頼度（0〜100%）と代替トークン候補が表示される。LLM の確信度を確認したい場合に有効 |
| `思考プロセスを非表示` | ON にすると thinking model の思考プロセス折りたたみブロックを完全に非表示にする |

#### セクション `音声`
| 項目 | 説明 |
|------|------|
| `音声読み上げを有効にする` | TTS 機能の有効/無効（デフォルト: OFF） |
| `新しい応答を自動読み上げ` | 応答完了後の自動読み上げ（デフォルト: OFF） |
| `音声` | 使用する音声を選択する。日本語音声が優先表示される |
| `読み上げ速度` | 0.5〜2.0 倍速（デフォルト: 1.0） |

#### セクション `接続`
| 項目 | 説明 |
|------|------|
| `Base URL` | LM Studio サーバーのアドレス（デフォルト: `http://localhost:1234/v1`） |
| `API Key` | API キー（デフォルト: `lmstudio`） |
| `Temperature` | 応答のランダム性（0.0〜2.0、デフォルト: 0.7）。低いほど決定的、高いほど創造的 |
| `Max Tokens` | 最大応答トークン数（デフォルト: 2048） |
| `Reasoning Effort` | 推論モデルの思考深度。`off`（デフォルト）/ `low` / `medium` / `high`。gpt-oss-120B 等の reasoning 対応モデルで使用 |

### 20.2 設定 > プリセット

#### セクション `System Prompt`
システムプロンプトの編集・管理を行う。
- `System Prompt` — テキストエリアで直接編集する
- `プリセット選択` — 保存済みプリセットを選択して読み込む
- `新規保存名` — 新しいプリセットとして保存する際の名前を入力する
- `適用` — 編集したプロンプトを現在の会話に適用する
- `保存` — 現在の内容をプリセットとして保存する
- `削除` — 選択中のプリセットを削除する

#### セクション `プリセット管理`
送信時に挿入できるプリセットプロンプトの管理を行う。
- `プリセット選択` — 編集するプリセットを選択する
- `キー` — プリセットの識別子（例: `disease`）
- `表示名` — ポップオーバーに表示される名前
- `内容` — プリセットの本文
- `新規追加` / `保存` / `削除` / `デフォルト復元`

### 20.3 設定 > データ

#### セクション `リセット`
| ボタン | 機能 |
|--------|------|
| `設定をデフォルトに戻す` | 全設定を初期値にリセットする |
| `すべての保存データを消す` | 設定・会話ログ・メモリーを含む全データを削除する |

#### セクション `メモリー管理`
- 保存メモリー件数が表示される。
- `メモリー全削除` で一括削除。
- 個別メモリーは `削除` ボタンで削除できる。

#### セクション `表示モデル管理`
- `すべて表示` / `すべて非表示`
- モデルチェックリストでチェック ON のモデルだけが上部の `モデルを選択` に表示される。多数のモデルがある場合に不要なモデルを非表示にできる。

#### セクション `会話ログ管理`
| ボタン | 機能 |
|--------|------|
| `新規チャットを作成` | 新しい空の会話を作成する |
| `ログエクスポート` | 全会話ログを JSON 形式でダウンロードする |
| `Markdown出力` | 現在の会話を Markdown 形式でダウンロードする。メッセージごとのメタデータ（モデル名・速度・トークン数）も含まれる |
| `ログインポート` | エクスポート済み JSON ファイルをインポートして会話を復元する（最大 10 MB） |

保存ログ一覧では各会話に対して `再開`（その会話を開く）または `削除` を実行できる。表示中の会話には `表示中` ラベルが付く。

### 20.4 設定 > Web検索

#### セクション `Web検索 (SearXNG)`
| 項目 | 説明 |
|------|------|
| `Web検索を有効にする` | SearXNG 連携の ON/OFF |
| `SearXNG URL` | SearXNG サーバーのアドレス（デフォルト: `http://localhost:8888`） |
| `検索結果数` | 取得する検索結果の件数（1〜10、デフォルト: 5） |
| `検索カテゴリ` | 検索対象のカテゴリ。general（一般）、science（学術）、news（ニュース）、it（技術）、files（ファイル）、images（画像）、videos（動画）から選択 |

## 21. キーボードショートカット
| ショートカット | 機能 |
|----------------|------|
| `⌘/Ctrl + K` | 新規チャット |
| `⌘/Ctrl + F` | 会話検索 |
| `⌘/Ctrl + /` | ショートカット一覧を表示 |
| `⌘/Ctrl + ,` | 設定を開く |
| `⌘/Ctrl + Shift + D` | ダークモード切替 |
| `⌘/Ctrl + Shift + C` | 比較モード切替 |
| `⌘/Ctrl + Shift + W` | Web検索切替 |
| `⌘/Ctrl + Shift + B` | ブックマーク一覧 |
| `⌘/Ctrl + Shift + T` | 自動読み上げ切替 |
| `Esc` | パネル・検索を閉じる |
| `Shift+Enter` または `Enter` | 送信（設定による） |
| `Cmd+V` / `Ctrl+V` | クリップボードから画像を貼り付け |

## 22. トラブルシューティング

### `モデルを選択` のままで選べない
1. LM Studio が起動しているか確認する。
2. `設定` > `接続` の `Base URL` が正しいか確認する（デフォルト: `http://localhost:1234/v1`）。
3. 上部の `モデル更新` を押す。

### 比較表示が期待と違う
1. `比較モード` を OFF → ON にする。
2. `Model A` と `Model B` を選び直して送信する。

### 画像を送信しても応答に画像の内容が含まれない
1. Vision 対応モデルを選択しているか確認する（`[Vision]` ラベルがあるもの）。
2. Vision 非対応モデルでは画像データは API に送信されない。
3. LM Studio 側でマルチモーダル対応モデルがロードされているか確認する。

### ストレージ容量不足の警告が出る
1. ブラウザの localStorage 容量（通常 5 MB）を超えると警告が表示される。
2. `設定` > `データ` > `会話ログ管理` から不要な会話ログを削除する。
3. 画像データは localStorage には保存されない（セッション中のみ保持）。

### PDF のテキストが抽出されない
1. スキャン画像のみの PDF はテキスト抽出できない。
2. ブラウザのコンソールでエラーを確認する。
3. PDF のサイズが 10 MB 以内であることを確認する。

### 数式が正しく表示されない
1. ブラウザをリロードして KaTeX ライブラリが読み込まれているか確認する。
2. 数式が `$...$` や `$$...$$` などのデリミタで囲まれているか確認する。
3. デリミタなしのテキスト数式はレンダリング対象外。

### Web検索が動作しない
1. SearXNG サーバーが起動しているか確認する。
2. `設定` > `Web検索` タブの `SearXNG URL` が正しいか確認する。
3. `Web検索を有効にする` が ON になっているか確認する。
4. 入力エリアの `Web検索` ボタンも ON にする必要がある。
